{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Decision Tree for Loan Default Prediction\n",
    "\n",
    "**AN6001 - AI & Big Data in Business**  \n",
    "**Author**: Mingkai Wang (#G2401001J)  \n",
    "**Date**: December 2, 2024\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project implements an intelligent loan default prediction system using decision tree algorithms. The system analyzes employment status, bank balance, and annual salary to assess default risk for financial institutions.\n",
    "\n",
    "### Key Features:\n",
    "- Binary classification for loan default prediction\n",
    "- Feature importance analysis for risk factors\n",
    "- Comprehensive model evaluation metrics\n",
    "- Real-world financial dataset with 10,000+ records\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix, \n",
    "    roc_curve, auc, precision_recall_curve\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(\"AI Decision Tree Loan Prediction System initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration\n",
    "\n",
    "Loading the loan default dataset with employment, financial, and default status information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the loan default dataset\n",
    "df = pd.read_csv('loan_default_data.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration and summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(f\"\\nDefault distribution:\")\n",
    "print(df['Defaulted?'].value_counts())\n",
    "print(f\"\\nDefault rate: {df['Defaulted?'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nEmployment status distribution:\")\n",
    "print(df['Employed'].value_counts())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "Analyzing the relationships between features and loan defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive EDA visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Default rate by employment status\n",
    "default_by_employment = df.groupby('Employed')['Defaulted?'].mean()\n",
    "axes[0, 0].bar(['Unemployed', 'Employed'], default_by_employment.values, \n",
    "               color=['red', 'green'], alpha=0.7)\n",
    "axes[0, 0].set_title('Default Rate by Employment Status')\n",
    "axes[0, 0].set_ylabel('Default Rate')\n",
    "\n",
    "# Bank balance distribution by default status\n",
    "df.boxplot(column='Bank Balance', by='Defaulted?', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Bank Balance Distribution by Default Status')\n",
    "axes[0, 1].set_xlabel('Defaulted? (0=No, 1=Yes)')\n",
    "\n",
    "# Annual salary distribution by default status\n",
    "df.boxplot(column='Annual Salary', by='Defaulted?', ax=axes[0, 2])\n",
    "axes[0, 2].set_title('Annual Salary Distribution by Default Status')\n",
    "axes[0, 2].set_xlabel('Defaulted? (0=No, 1=Yes)')\n",
    "\n",
    "# Correlation heatmap\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Feature Correlation Matrix')\n",
    "\n",
    "# Default distribution\n",
    "default_counts = df['Defaulted?'].value_counts()\n",
    "axes[1, 1].pie(default_counts.values, labels=['No Default', 'Default'], \n",
    "               autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'])\n",
    "axes[1, 1].set_title('Overall Default Distribution')\n",
    "\n",
    "# Scatter plot: Bank Balance vs Annual Salary colored by default\n",
    "colors = ['green' if x == 0 else 'red' for x in df['Defaulted?']]\n",
    "axes[1, 2].scatter(df['Bank Balance'], df['Annual Salary'], c=colors, alpha=0.6)\n",
    "axes[1, 2].set_xlabel('Bank Balance')\n",
    "axes[1, 2].set_ylabel('Annual Salary')\n",
    "axes[1, 2].set_title('Bank Balance vs Annual Salary (Green=No Default, Red=Default)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Exploratory Data Analysis completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Data Preprocessing\n",
    "\n",
    "Preparing the data for machine learning model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "def create_features(data):\n",
    "    \"\"\"Create additional features for better prediction\"\"\"\n",
    "    df_features = data.copy()\n",
    "    \n",
    "    # Create debt-to-income ratio (assuming bank balance represents available funds)\n",
    "    df_features['Debt_to_Income'] = (df_features['Annual Salary'] - df_features['Bank Balance']) / df_features['Annual Salary']\n",
    "    df_features['Debt_to_Income'] = df_features['Debt_to_Income'].clip(0, 1)  # Cap at 100%\n",
    "    \n",
    "    # Create financial stability indicator\n",
    "    df_features['Financial_Stability'] = df_features['Bank Balance'] / (df_features['Annual Salary'] + 1)\n",
    "    \n",
    "    # Create income categories\n",
    "    income_quantiles = df_features['Annual Salary'].quantile([0.33, 0.67])\n",
    "    df_features['Income_Category'] = pd.cut(df_features['Annual Salary'], \n",
    "                                           bins=[0, income_quantiles.iloc[0], income_quantiles.iloc[1], float('inf')],\n",
    "                                           labels=['Low', 'Medium', 'High'])\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le = LabelEncoder()\n",
    "    df_features['Income_Category_Encoded'] = le.fit_transform(df_features['Income_Category'])\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# Apply feature engineering\n",
    "df_engineered = create_features(df)\n",
    "\n",
    "print(\"Feature engineering completed\")\n",
    "print(f\"New features created: Debt_to_Income, Financial_Stability, Income_Category\")\n",
    "print(f\"Dataset shape after feature engineering: {df_engineered.shape}\")\n",
    "\n",
    "# Display new features\n",
    "print(\"\\nNew feature statistics:\")\n",
    "print(df_engineered[['Debt_to_Income', 'Financial_Stability']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target variable\n",
    "feature_columns = ['Employed', 'Bank Balance', 'Annual Salary', \n",
    "                  'Debt_to_Income', 'Financial_Stability', 'Income_Category_Encoded']\n",
    "\n",
    "X = df_engineered[feature_columns]\n",
    "y = df_engineered['Defaulted?']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns: {feature_columns}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Training set default rate: {y_train.mean():.4f}\")\n",
    "print(f\"Test set default rate: {y_test.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model Training and Optimization\n",
    "\n",
    "Training and optimizing the decision tree classifier for loan default prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple decision tree models with different parameters\n",
    "models = {\n",
    "    'Default': DecisionTreeClassifier(random_state=42),\n",
    "    'Max_Depth_5': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    'Max_Depth_10': DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "    'Min_Samples_Split_10': DecisionTreeClassifier(min_samples_split=10, random_state=42),\n",
    "    'Balanced': DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name} Decision Tree...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"   CV Score: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\")\n",
    "\n",
    "# Select best model\n",
    "best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f\"\\nBest performing model: {best_model_name}\")\n",
    "print(f\"Best accuracy: {results[best_model_name]['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Performance Analysis\n",
    "\n",
    "Comprehensive evaluation of the decision tree model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation of the best model\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "best_probabilities = results[best_model_name]['probabilities']\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, best_predictions, \n",
    "                          target_names=['No Default', 'Default']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = best_model.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nFeature Importance:\")\n",
    "for _, row in importance_df.iterrows():\n",
    "    print(f\"   {row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive visualization of model performance\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Model comparison\n",
    "model_names = list(results.keys())\n",
    "accuracies = [results[name]['accuracy'] for name in model_names]\n",
    "cv_means = [results[name]['cv_mean'] for name in model_names]\n",
    "\n",
    "axes[0, 0].bar(model_names, accuracies, alpha=0.7, color='skyblue')\n",
    "axes[0, 0].set_title('Model Accuracy Comparison')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Cross-validation scores\n",
    "axes[0, 1].bar(model_names, cv_means, alpha=0.7, color='lightgreen')\n",
    "axes[0, 1].set_title('Cross-Validation Score Comparison')\n",
    "axes[0, 1].set_ylabel('CV Score')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 2])\n",
    "axes[0, 2].set_title(f'Confusion Matrix - {best_model_name}')\n",
    "axes[0, 2].set_xlabel('Predicted')\n",
    "axes[0, 2].set_ylabel('Actual')\n",
    "\n",
    "# Feature Importance\n",
    "axes[1, 0].barh(importance_df['feature'], importance_df['importance'])\n",
    "axes[1, 0].set_title('Feature Importance')\n",
    "axes[1, 0].set_xlabel('Importance')\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, best_probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "axes[1, 1].plot(fpr, tpr, color='darkorange', lw=2, \n",
    "                label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "axes[1, 1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes[1, 1].set_xlim([0.0, 1.0])\n",
    "axes[1, 1].set_ylim([0.0, 1.05])\n",
    "axes[1, 1].set_xlabel('False Positive Rate')\n",
    "axes[1, 1].set_ylabel('True Positive Rate')\n",
    "axes[1, 1].set_title('ROC Curve')\n",
    "axes[1, 1].legend(loc=\"lower right\")\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, best_probabilities)\n",
    "axes[1, 2].plot(recall, precision, color='blue', lw=2)\n",
    "axes[1, 2].set_xlabel('Recall')\n",
    "axes[1, 2].set_ylabel('Precision')\n",
    "axes[1, 2].set_title('Precision-Recall Curve')\n",
    "axes[1, 2].set_xlim([0.0, 1.0])\n",
    "axes[1, 2].set_ylim([0.0, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nModel Performance Summary:\")\n",
    "print(f\"   Best Model: {best_model_name}\")\n",
    "print(f\"   Accuracy: {results[best_model_name]['accuracy']:.4f}\")\n",
    "print(f\"   AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"   Cross-validation: {results[best_model_name]['cv_mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Visualization\n",
    "\n",
    "Visualizing the decision tree structure for interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simplified decision tree for visualization\n",
    "viz_tree = DecisionTreeClassifier(max_depth=4, min_samples_split=50, random_state=42)\n",
    "viz_tree.fit(X_train, y_train)\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(20, 12))\n",
    "plot_tree(viz_tree, \n",
    "          feature_names=feature_columns,\n",
    "          class_names=['No Default', 'Default'],\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title('Decision Tree Visualization (Simplified)', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Tree statistics\n",
    "print(f\"Decision Tree Statistics:\")\n",
    "print(f\"   Tree depth: {viz_tree.get_depth()}\")\n",
    "print(f\"   Number of leaves: {viz_tree.get_n_leaves()}\")\n",
    "print(f\"   Number of nodes: {viz_tree.tree_.node_count}\")\n",
    "\n",
    "# Evaluate simplified tree\n",
    "viz_predictions = viz_tree.predict(X_test)\n",
    "viz_accuracy = accuracy_score(y_test, viz_predictions)\n",
    "print(f\"   Simplified tree accuracy: {viz_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretation and Business Insights\n",
    "\n",
    "Extracting actionable insights from the decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business insights and model interpretation\n",
    "print(\"=\" * 60)\n",
    "print(\"LOAN DEFAULT PREDICTION - BUSINESS INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Risk factor analysis\n",
    "print(\"\\n1. KEY RISK FACTORS (by importance):\")\n",
    "for i, (_, row) in enumerate(importance_df.iterrows(), 1):\n",
    "    print(f\"   {i}. {row['feature']}: {row['importance']:.3f}\")\n",
    "\n",
    "# Employment impact\n",
    "employment_default_rates = df_engineered.groupby('Employed')['Defaulted?'].agg(['mean', 'count'])\n",
    "print(f\"\\n2. EMPLOYMENT STATUS IMPACT:\")\n",
    "print(f\"   Unemployed default rate: {employment_default_rates.loc[0, 'mean']:.3f} ({employment_default_rates.loc[0, 'count']} cases)\")\n",
    "print(f\"   Employed default rate: {employment_default_rates.loc[1, 'mean']:.3f} ({employment_default_rates.loc[1, 'count']} cases)\")\n",
    "\n",
    "# Financial metrics analysis\n",
    "defaulters = df_engineered[df_engineered['Defaulted?'] == 1]\n",
    "non_defaulters = df_engineered[df_engineered['Defaulted?'] == 0]\n",
    "\n",
    "print(f\"\\n3. FINANCIAL PROFILE COMPARISON:\")\n",
    "print(f\"   Average Bank Balance - Defaulters: ${defaulters['Bank Balance'].mean():,.2f}\")\n",
    "print(f\"   Average Bank Balance - Non-defaulters: ${non_defaulters['Bank Balance'].mean():,.2f}\")\n",
    "print(f\"   Average Annual Salary - Defaulters: ${defaulters['Annual Salary'].mean():,.2f}\")\n",
    "print(f\"   Average Annual Salary - Non-defaulters: ${non_defaulters['Annual Salary'].mean():,.2f}\")\n",
    "\n",
    "# Model performance summary\n",
    "print(f\"\\n4. MODEL PERFORMANCE:\")\n",
    "print(f\"   Overall Accuracy: {results[best_model_name]['accuracy']:.3f}\")\n",
    "print(f\"   Cross-validation Score: {results[best_model_name]['cv_mean']:.3f}\")\n",
    "print(f\"   AUC Score: {roc_auc:.3f}\")\n",
    "\n",
    "# Prediction examples\n",
    "print(f\"\\n5. SAMPLE PREDICTIONS:\")\n",
    "sample_indices = np.random.choice(X_test.index, 5, replace=False)\n",
    "for idx in sample_indices:\n",
    "    actual = y_test.loc[idx]\n",
    "    predicted = best_model.predict(X_test.loc[[idx]])[0]\n",
    "    probability = best_model.predict_proba(X_test.loc[[idx]])[0][1]\n",
    "    \n",
    "    print(f\"   Case {idx}: Actual={actual}, Predicted={predicted}, Default Prob={probability:.3f}\")\n",
    "    print(f\"      Employment={X_test.loc[idx, 'Employed']}, Balance=${X_test.loc[idx, 'Bank Balance']:,.0f}, Salary=${X_test.loc[idx, 'Annual Salary']:,.0f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment Recommendations\n",
    "\n",
    "Practical recommendations for implementing the loan default prediction system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment recommendations\n",
    "print(\"DEPLOYMENT RECOMMENDATIONS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "recommendations = [\n",
    "    \"1. RISK THRESHOLD SETTING:\",\n",
    "    \"   - Set default probability threshold at 0.3 for high sensitivity\",\n",
    "    \"   - Monitor false positive rates to balance risk and business impact\",\n",
    "    \"\",\n",
    "    \"2. FEATURE MONITORING:\",\n",
    "    f\"   - Primary focus: {importance_df.iloc[0]['feature']} (highest importance)\",\n",
    "    \"   - Regular updates needed for employment status verification\",\n",
    "    \"   - Automated financial data validation\",\n",
    "    \"\",\n",
    "    \"3. MODEL MAINTENANCE:\",\n",
    "    \"   - Retrain quarterly with new default data\",\n",
    "    \"   - Monitor for concept drift in economic conditions\",\n",
    "    \"   - A/B test model updates before full deployment\",\n",
    "    \"\",\n",
    "    \"4. BUSINESS INTEGRATION:\",\n",
    "    \"   - Integrate with existing loan approval workflow\",\n",
    "    \"   - Provide explanation capabilities for loan officers\",\n",
    "    \"   - Implement feedback loop for prediction accuracy tracking\"\n",
    "]\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(rec)\n",
    "\n",
    "# Save model performance metrics\n",
    "performance_summary = {\n",
    "    'model_type': 'Decision Tree Classifier',\n",
    "    'best_model': best_model_name,\n",
    "    'accuracy': results[best_model_name]['accuracy'],\n",
    "    'cv_score': results[best_model_name]['cv_mean'],\n",
    "    'auc_score': roc_auc,\n",
    "    'feature_importance': importance_df.to_dict('records'),\n",
    "    'training_samples': len(X_train),\n",
    "    'test_samples': len(X_test)\n",
    "}\n",
    "\n",
    "print(f\"\\nModel training completed successfully!\")\n",
    "print(f\"Performance summary saved for deployment reference.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}